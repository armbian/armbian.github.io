name: Sync 3rd party packages
on:
  workflow_dispatch:
  workflow_call:
    inputs:
      ACCESS_NAME:
        required: false
        type: string
        default: ${{ github.repository_owner }}
      BUILD_BRANCH:
        required: false
        type: string
        default: 'main'
      BUILD_RUNNER:
        required: false
        type: string
        default: "ubuntu-latest"
      HOST_DEPLOY:
        required: false
        type: string
        default: "repo.armbian.com"
      HOST_USER:
        required: false
        type: string
        default: "upload"
      REFERENCE:
        required: false
        type: string
        default: "main"
      HIDE_NO_UPDATE:
        required: false
        type: boolean
        default: false
      PURGE:
        required: false
        type: boolean
        default: false
    secrets:
      GPG_KEY1:
        required: true
      GPG_KEY2:
        required: true
      ACCESS_TOKEN:
        required: true
      KEY_UPLOAD:
        required: false
      HOST_UPLOAD:
        required: true
      HOST_UPLOAD_USER:
        required: true
      HOST_UPLOAD_PORT:
        required: true
      KNOWN_HOSTS_ARMBIAN_UPLOAD:
        required: true

env:
  GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  PR_NUMBER: ${{ github.event.number }}

jobs:

  perm:
    name: "Restore permissions"
    runs-on: repository-sync
    steps:
      - name: "Restore permissions"
        run: |

          sudo chown -R ${{ secrets.HOST_UPLOAD_USER }}:${{ secrets.HOST_UPLOAD_USER }} /armbian/openssh-server/storage/{debs,debs-beta,artifacts}

  preclean:
    name: "Purge"
    needs: perm
    if: ${{ inputs.PURGE == true }}
    runs-on: ubuntu-latest
    outputs:
      matrix:  ${{steps.json.outputs.JSON_CONTENT}}
    steps:
      - name: "Checkout Armbian build Framework"
        uses: actions/checkout@v5
        with:
          repository: armbian/build
          ref: ${{ inputs.REFERENCE || inputs.branch || 'main' }}
          clean: false
          fetch-depth: 1
          path: build

      - name: "Make JSON"
        id: json
        run: |

          pkg="code,codium,google-chrome-stable,anubis,armbian-config,box64,box64-android,gh,min,microsoft-edge-stable,zoom,armbian-firmware,armbian-firmware-full"
          echo 'JSON_CONTENT<<EOF' >> $GITHUB_OUTPUT
          releases=($(grep "supported\|csc" build/config/distributions/*/support | cut -d"/" -f4))
          for i in ${releases[@]}; do
              packages=($(echo "$pkg" | tr ',' '\n'))
                  for j in ${packages[@]}; do
                      echo "{\"release\":\"${i}\",\"package\":\"$j\"}"
                  done
              done | jq -s >> $GITHUB_OUTPUT
          echo 'EOF' >> $GITHUB_OUTPUT

  postclean:
    needs: preclean
    if: ${{ inputs.PURGE == true }}
    strategy:
      fail-fast: false
      max-parallel: 1
      matrix:
        include: ${{ fromJson(needs.preclean.outputs.matrix) }}

    name: "Purge old ${{ matrix.package }} from ${{ matrix.release }}"
    timeout-minutes: 60
    runs-on: repository
    steps:

      - name: Checkout build repository
        uses: actions/checkout@v5
        with:
          repository: armbian/build
          fetch-depth: 1
          clean: false

      - name: Purge packages
        run: |

          # take ownership
          sudo chown -R ${USER}:${USER} /outgoing/repository

          PKG="${{ matrix.package }}"

          LIST=$(
            tools/repository/repo -i /incoming/debs -o /outgoing/repository -r ${{ matrix.release }} \
              | sed 's/^[[:space:]]*//' \
              | grep "^${PKG}_" || true
          )

          COUNT=$(printf "%s\n" "$LIST" | grep -c . || true)

          if (( COUNT > 1 )); then
              # Display & log header
              echo "Found $COUNT packages for $PKG â€” deleting older versions" \
                | tee -a "$GITHUB_STEP_SUMMARY" >/dev/null

              # Determine newest version
              LATEST=$(printf "%s\n" "$LIST" | sort -V | tail -n 1)

              VERSION="${LATEST#${PKG}_}"   # strip pkg_
              VERSION="${VERSION%_*}"       # strip _ARCH

              echo "Newest version: $VERSION" \
                | tee -a "$GITHUB_STEP_SUMMARY" >/dev/null

              # Pretty print command in both outputs
              {
                echo '### ðŸ§¹ Delete package'
                echo '```bash'
                echo "tools/repository/repo -o /outgoing/repository -r ${{ matrix.release }} -c delete -l 'Name (= $PKG), \$Version (<< $VERSION)'"
                echo '```'
              } | tee -a "$GITHUB_STEP_SUMMARY" >/dev/null

              # === RUN DELETE OPERATION ===
              tools/repository/repo -i /incoming/debs -o /outgoing/repository -r ${{ matrix.release }} -c delete -l "Name (= $PKG), \$Version (<< $VERSION)"

          else
              echo "Only $COUNT package present â€” skipping delete" \
                | tee -a "$GITHUB_STEP_SUMMARY" >/dev/null
          fi

  start:
    runs-on: ${{ inputs.BUILD_RUNNER }}
    needs: perm
    name: "Mirror"
    outputs:
      matrix: ${{steps.lists.outputs.matrix}}
    steps:

      - name: Install SSH key
        uses: shimataro/ssh-key-action@v2
        with:
          key: ${{ secrets.KEY_UPLOAD }}
          known_hosts: ${{ secrets.KNOWN_HOSTS_ARMBIAN_UPLOAD }}
          if_key_exists: replace

      - name: Create a temporary artifact folder
        run: |
          mkdir -p downloads
          cd downloads
          echo "${{ inputs.HOST_DEPLOY }}/" > url.txt
          echo "artifacts/${{ env.PR_NUMBER }}/" > path.txt

      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: assets-for-download
          path: downloads
          overwrite: true
          retention-days: 5

      - name: Remove temporary repositories
        run: |
          # Note: StrictHostKeychecking=no is used here; consider using proper known_hosts in production
          ssh -o StrictHostKeychecking=no -p ${{ secrets.HOST_UPLOAD_PORT }} \
            ${{ inputs.HOST_USER }}@${{ inputs.HOST_DEPLOY }} \
            "rm -rf storage/artifacts/*"

      - name: Checkout Armbian OS repository
        uses: actions/checkout@v4
        with:
          repository: armbian/os
          path: os
          fetch-depth: '2'
          clean: false

      - name: Get changed files
        id: changed-files
        uses: tj-actions/changed-files@v47
        with:
          path: os
          files: |
            external/*.conf

      - name: Build list
        id: lists
        run: |
          # Install jq if not available
          command -v jq >/dev/null 2>&1 || sudo apt-get install -y jq

          echo "::debug::Changed files: ${{ steps.changed-files.outputs.all_changed_files }}" >&2
          echo "::debug::REFERENCE input: ${{ inputs.REFERENCE }}" >&2

          # Build list of conf files
          if [[ "${{ inputs.REFERENCE }}" =~ ^(main|)$ ]]; then
            # Get all conf files
            MATRIX_LIST=()
            while IFS= read -r -d '' conf_file; do
              conf_name=$(basename "$conf_file" .conf)
              MATRIX_LIST+=("$conf_name")
            done < <(find os/external/*.conf -print0 | sort -z)
          else
            # Get only changed conf files
            MATRIX_LIST=()
            CHANGED="${{ steps.changed-files.outputs.all_changed_files }}"
            if [[ -n "$CHANGED" ]]; then
              while IFS= read -r conf_file; do
                conf_name=$(echo "$conf_file" | cut -d"." -f1 | cut -d"/" -f2)
                MATRIX_LIST+=("$conf_name")
              done < <(echo "$CHANGED" | tr " " "\n")
            fi
          fi

          echo "::debug::MATRIX content: ${MATRIX_LIST[*]}" >&2

          # Build detailed matrix - expand each arch and release combination
          echo "::notice::Building matrix..." >&2

          MATRIX_JSON=$(
          for conf_file in "${MATRIX_LIST[@]}"; do
            echo "::debug::Processing conf file: ${conf_file}" >&2
            [[ -f "os/external/${conf_file}.conf" ]] || continue

            # Source the conf file to get variables
            . "os/external/${conf_file}.conf"

            echo "::debug::${conf_file} - ARCH: ${ARCH}, RELEASE: ${RELEASE}, TARGET: ${TARGET}" >&2

            # Expand architectures (colon-separated)
            archs=($(echo "$ARCH" | tr ':' ' '))

            # Expand releases
            if [[ "${RELEASE}" == "all" ]]; then
              # Default releases for "all"
              releases=("bookworm" "trixie" "forky" "jammy" "noble")
            elif [[ "${RELEASE}" == *":"* ]]; then
              # Colon-separated releases
              IFS=':' read -ra releases <<< "$RELEASE"
            else
              # Single release
              releases=("$RELEASE")
            fi

            # Generate matrix entry for each arch x release combination
            for arch in "${archs[@]}"; do
              for release in "${releases[@]}"; do
                # Determine if we need QEMU (non-amd64)
                needs_qemu="false"
                [[ "$arch" != "amd64" ]] && needs_qemu="true"

                echo "::debug::Generating entry: package=${conf_file}, arch=${arch}, release=${release}, needs_qemu=${needs_qemu}" >&2

                # Determine runner based on architecture and method
                # Force amd64 runner for aptly method due to stability issues on ARM
                if [[ "${METHOD:-aptly}" == "aptly" ]]; then
                  # Always use amd64 runner for aptly, use QEMU for other arches
                  runner="ubuntu-latest"
                  image_arch="amd64"
                else
                  # Use architecture-specific runners for other methods (gh, direct)
                  case "${arch}" in
                    amd64)
                      runner="ubuntu-latest"
                      image_arch="${arch}"
                      ;;
                    arm64)
                      runner="ubuntu-24.04-arm"
                      image_arch="${arch}"
                      ;;
                    armhf|riscv64)
                      runner="ubuntu-latest"
                      image_arch="amd64"  # Use amd64 image with QEMU emulation
                      ;;
                    *)
                      runner="ubuntu-latest"
                      image_arch="amd64"
                      ;;
                  esac
                fi

                # Output JSON object for this combination - use pre-built Docker images
                jq -n \
                  --arg name "${conf_file}" \
                  --arg arch "${arch}" \
                  --arg release "${release}" \
                  --arg target "${TARGET:-main}" \
                  --arg method "${METHOD:-aptly}" \
                  --arg install "${INSTALL:-}" \
                  --arg runner "${runner}" \
                  --arg image_arch "${image_arch}" \
                  --arg registry "ghcr.io/${{ github.repository_owner }}" \
                  --argjson needs_qemu "${needs_qemu}" \
                  '{name: $name, arch: $arch, release: $release, target: $target, method: $method, install: $install, runner: $runner, image_arch: $image_arch, registry: $registry, needs_qemu: $needs_qemu}'
              done
            done
          done | jq -s '{"include": .}'
          )

          # Check if matrix is valid
          MATRIX_COUNT=$(echo "${MATRIX_JSON}" | jq '.include | length')

          # Handle empty matrix - add a dummy entry that will be skipped
          if [[ "${MATRIX_COUNT}" -eq 0 ]]; then
            echo "::warning::No matrix entries generated, adding placeholder" >&2
            MATRIX_JSON_COMPACTED='{"include":[{"name":"none","arch":"amd64","release":"bookworm"}]}'
          else
            # Debug: Show raw matrix JSON
            echo "::debug::Raw matrix JSON: ${MATRIX_JSON}" >&2

            # Compact the JSON for GitHub Actions
            MATRIX_JSON_COMPACTED=$(echo "${MATRIX_JSON}" | jq -c)
            echo "::debug::Compacted matrix JSON: ${MATRIX_JSON_COMPACTED}" >&2
          fi

          echo "matrix=${MATRIX_JSON_COMPACTED}" >> $GITHUB_OUTPUT

  download:
    needs: [start]
    outputs:
      project: ${{steps.make.outputs.project}}
    strategy:
      fail-fast: false
      max-parallel: 64
      matrix: ${{fromJson(needs.start.outputs.matrix)}}

    name: "${{ matrix.name }}:${{ matrix.release }}:${{ matrix.arch }}"
    runs-on: ${{ matrix.runner }}
    container:
      image: ${{ matrix.registry }}/repository-update:${{ matrix.release }}-${{ matrix.image_arch }}
      options: --user root
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    steps:

      - name: Install SSH key
        uses: shimataro/ssh-key-action@v2
        with:
          key: ${{ secrets.KEY_UPLOAD }}
          known_hosts: ${{ secrets.KNOWN_HOSTS_ARMBIAN_UPLOAD }}
          if_key_exists: replace

      - name: Import GPG key 1
        uses: crazy-max/ghaction-import-gpg@v6
        env:
          HOME: /root
          GNUPGHOME: /root/.gnupg
        with:
          gpg_private_key: ${{ secrets.GPG_KEY1 }}

      - name: Import GPG key 2
        uses: crazy-max/ghaction-import-gpg@v6
        with:
          gpg_private_key: ${{ secrets.GPG_KEY2 }}

      - name: Checkout Armbian OS scripts
        uses: actions/checkout@v4
        with:
          repository: armbian/os
          path: os
          ref: ${{ inputs.REFERENCE }}
          fetch-depth: '1'
          clean: false

      - name: Checkout Armbian build script
        uses: actions/checkout@v4
        with:
          repository: armbian/build
          path: build
          fetch-depth: '1'
          clean: false

      - name: Install GPG keys
        shell: bash
        run: |
          # Import all GPG keys from the repository
          find os/external/keys/ -type f -name "*.gpg" -exec gpg --import --no-default-keyring --keyring trustedkeys.gpg "{}" \;

          # Install appropriate keyring based on container type
          if grep -q "debian" /etc/os-release; then
            apt-get -y install debian-keyring
          elif grep -q "ubuntu" /etc/os-release; then
            apt-get -y install ubuntu-keyring
          fi

          # Import additional keys
          gpg --no-default-keyring --keyring trustedkeys.gpg \
            --keyserver keyserver.ubuntu.com \
            --recv-keys 648ACFD622F3D138 0E98404D386FA1D9

      - name: "Prepare machine"
        id: preparing
        shell: bash
        run: |

          # Load configuration
          . os/external/${{ matrix.name }}.conf

          echo "::debug::Config loaded - URL: ${URL}, KEY: ${KEY}, INSTALL: ${INSTALL}, ARCH: ${ARCH}, RELEASE: ${RELEASE}"

          APTLY_CONF="-max-tries=3 "
          [[ "${CHECKSUM}" == "ignore" ]] && APTLY_CONF+="-ignore-checksums "
          [[ "${SIGNATURES}" == "ignore" ]] && APTLY_CONF+="-ignore-signatures "

          # Read existing releases and create folder structure
          ALL_RELEASES=($(grep -rw build/config/distributions/*/support -ve 'eos' | cut -d"/" -f4 ))
          for i in ${ALL_RELEASES[@]}; do
            mkdir -p build/output/{debs,debs-beta}/${i}
            mkdir -p build/output/{debs,debs-beta}/extra/${i}-utils
            mkdir -p build/output/{debs,debs-beta}/extra/${i}-desktop
          done

          needs_qemu='${{ matrix.needs_qemu }}'
          arch='${{ matrix.arch }}'
          release='${{ matrix.release }}'

          # Configure Ubuntu foreign architecture sources (only needed for aptly method)
          if [[ -r /etc/os-release ]]; then
            . /etc/os-release
            if [[ "${ID:-}" == "ubuntu" ]]; then
              # Only add foreign arch sources when needed
              if [[ "$needs_qemu" == "true" && "$arch" != "amd64" ]]; then
                # Enable foreign architecture
                dpkg --add-architecture "$arch"

                SRC="/etc/apt/sources.list.d/ubuntu-${arch}.sources"
                KEYRING="/usr/share/keyrings/ubuntu-archive-keyring.gpg"

                # Create source only if it does not exist
                if [[ ! -f "$SRC" ]]; then
                  printf '%s\n' \
                    "Types: deb" \
                    "URIs: http://ports.ubuntu.com/ubuntu-ports" \
                    "Suites: ${release} ${release}-updates ${release}-backports" \
                    "Components: main restricted universe multiverse" \
                    "Architectures: ${arch}" \
                    "Signed-By: ${KEYRING}" \
                    > "$SRC"
                fi
              fi
            fi
          fi

      - name: "Download method: ${{ matrix.method }}"
        id: calculate
        shell: bash
        run: |

          # Load configuration
          . os/external/${{ matrix.name }}.conf

          SOURCE="temp/"
          mkdir -p ${SOURCE}

          # Get current version from Armbian repository
          PKG="${INSTALL%% *}"

          # Determine the repository component based on TARGET
          if [[ "${TARGET}" == "main" ]]; then
            COMPONENT="main"
          else
            COMPONENT="extra/${{ matrix.release }}-${TARGET}"
          fi

          # Get version from main repository
          BEFORE_VERSION=""

          # Try main component, desktop component, then extra component
          for repo_component in "main" "${{ matrix.release }}-desktop" "${{ matrix.release }}-utils"; do
            # Build URL for Packages index
            #PACKAGES_URL="http://apt.armbian.com/dists/${{ matrix.release }}/${repo_component}/binary-${{ matrix.arch }}/Packages.gz"
            PACKAGES_URL="http://fi.mirror.armbian.de/apt/dists/${{ matrix.release }}/${repo_component}/binary-${{ matrix.arch }}/Packages.gz"

            echo "::debug::Trying $PACKAGES_URL"

            # Download and parse the package index
            # Use || true to prevent SIGPIPE when wget fails (404)
            # shellcheck disable=SC2002
            BEFORE_VERSION="$(wget --timeout=10 --tries=3 -qO- "$PACKAGES_URL" 2>/dev/null | \
              gunzip 2>/dev/null | \
              awk -v pkg="$PKG" '
                /^Package: / { pkg_name = $2 }
                /^Version: / { if (pkg_name == pkg) { print $2; exit } }
              ')" || true

            if [[ -n "$BEFORE_VERSION" ]]; then
              echo "::notice::Found $PKG version $BEFORE_VERSION in ${repo_component}"
              break
            fi
          done

          if [[ -z "$BEFORE_VERSION" ]]; then
            echo "::warning::Could not find version for $PKG in repository, assuming new package"
            BEFORE_VERSION="0"
          fi

          echo "BEFORE_VERSION=${BEFORE_VERSION}" >> $GITHUB_OUTPUT
          
          # Download packages based on method
          if [[ ${METHOD} == gh ]]; then
            # GitHub release download method
            case "${{ matrix.arch }}" in
              amd64)
                PATTERNS+=('*amd64*.deb' '*x86_64*.deb' '*x64*.deb')
                ;;
              arm64)
                PATTERNS+=('*arm64*.deb' '*aarch64*.deb')
                ;;
              armhf)
                PATTERNS+=('*armhf*.deb' '*armv7*.deb' '*armv7l*.deb' '*armv6*.deb')
                ;;
              riscv64)
                PATTERNS+=('*riscv64*.deb')
                ;;
              *)
                echo "Unsupported arch: ${{ matrix.arch }}" >&2
                exit 1
                ;;
            esac

            # exception
            if [[ "${{ matrix.name }}" == "haos-supervised-installer" ]]; then
                PATTERNS=('*.deb')
            fi

            echo "Downloading from GitHub release ${TAG}"
            for p in "${PATTERNS[@]}"; do
              echo "  gh release download ${TAG} -p '$p' --repo ${URL}"
              gh release download "${TAG}" \
                -p "$p" \
                --repo "${URL}" \
                --dir "${SOURCE}" || true
            done

            # exception
            if [[ "${{ matrix.name }}" == "fastfetch" ]]; then
                rm -f "${SOURCE}"*polyfilled*
                rm -f "${SOURCE}"*armv6l.deb
            fi

            # Check if any .deb files were downloaded
            if ! ls "${SOURCE}"*.deb &> /dev/null; then
              echo "::error::No .deb files were downloaded for ${{ matrix.name }} on ${{ matrix.arch }}" >&2
              echo "Patterns tried: ${PATTERNS[*]}" >&2
              exit 1
            fi
          elif [[ ${METHOD} == direct ]]; then
            # Direct download method
            wget -O ${SOURCE}${{ matrix.name }}.deb ${URL}
            # Check if any .deb files were downloaded
            if ! ls "${SOURCE}"*.deb &> /dev/null; then
              echo "::error::No .deb files were downloaded for ${{ matrix.name }} on ${{ matrix.arch }}" >&2
              exit 1
            fi
          else
            # Aptly mirror method
            # Pin aptly state (critical in GH Actions containers)
            set -euo pipefail

            export HOME=/root
            APTLY_ROOT="/root/.aptly"
            APTLY_CFG="/root/.aptly.conf"
            mkdir -p "$APTLY_ROOT"
            printf '{ "rootDir": "%s" }\n' "$APTLY_ROOT" > "$APTLY_CFG"

            echo "::debug::APTLY_ROOT=$APTLY_ROOT"
            echo "::debug::APTLY_CFG=$APTLY_CFG"
            echo "::debug::Config file contents:"
            cat "$APTLY_CFG" >&2

            SOURCE="/root/.aptly/public/"

            # Configure filtering
            ADDITIONAL_FILTER=""
            FILTER_ARGS=()

            # Add -filter-with-deps only when filter does NOT include Name/Version
            if [[ "${GLOB:-}" != *Name* && "${GLOB:-}" != *Version* ]]; then
              ADDITIONAL_FILTER="-filter-with-deps"
            fi

            # Add filter only if GLOB is set/non-empty
            if [[ -n "${GLOB:-}" ]]; then
              FILTER_ARGS=(-filter="$GLOB")
            fi

            # Make mirror name unique per arch to avoid collisions
            MIRROR="${{ matrix.name }}-${{ matrix.release }}-${{ matrix.arch }}"

            echo "::debug::MIRROR_NAME=$MIRROR"
            echo "::debug::Original KEY='${KEY:-}'"

            # KEY may be:
            #   - "unstable contrib non-free"  (suite + components)
            #   - "bookworm"                  (suite only)
            #   - "./" / "public" / "stable"  (special/flat)
            read -r DIST REST <<<"${KEY:-}"
            COMPONENTS="$REST"

            echo "::debug::DIST='$DIST'"
            echo "::debug::REST='$REST'"
            echo "::debug::COMPONENTS='$COMPONENTS'"

            # Special/flat cases: do not pass components
            case "${KEY:-}" in
              "./"|"stable"|"public"|"stable non-free")
                DIST="$KEY"
                COMPONENTS=""
                ;;
            esac

            # If KEY did not include components, default to "main"
            if [[ -z "$COMPONENTS" && "$DIST" != "./" && "$DIST" != "stable" && "$DIST" != "public" && "$DIST" != "stable non-free" ]]; then
              COMPONENTS="main"
            fi

            echo "::debug::Final DIST='$DIST'"
            echo "::debug::Final COMPONENTS='$COMPONENTS'"

            # Prefer https (helps with EOF/proxy weirdness)
            URL="${URL:-}"
            URL="${URL/http:\/\//https:\/\/}"

            echo "::debug::URL='$URL'"
            echo "::debug::FILTER_ARGS='${FILTER_ARGS[*]}'"
            echo "::debug::ADDITIONAL_FILTER='$ADDITIONAL_FILTER'"
            echo "::debug::ARCH='${{ matrix.arch }}'"

            # Drop mirror if it already exists from previous run
            echo "::debug::Checking if mirror exists..."
            if aptly -config="$APTLY_CFG" mirror show "$MIRROR" &>/dev/null; then
              echo "::notice::Dropping existing mirror: $MIRROR"
              aptly -config="$APTLY_CFG" mirror drop "$MIRROR" || true
            else
              echo "::debug::Mirror does not exist yet"
            fi

            # Create mirror (distribution + optional components)
            echo "::debug::Creating mirror..."
            if [[ -n "$COMPONENTS" ]]; then
              echo "::debug::aptly -config="$APTLY_CFG" -ignore-signatures ${FILTER_ARGS[*]} ${ADDITIONAL_FILTER} -architectures="${{ matrix.arch }}" mirror create "$MIRROR" "$URL" "$DIST" $COMPONENTS"
              # shellcheck disable=SC2086
              aptly -config="$APTLY_CFG" -ignore-signatures "${FILTER_ARGS[@]}" $ADDITIONAL_FILTER -architectures="${{ matrix.arch }}" mirror create "$MIRROR" "$URL" "$DIST" $COMPONENTS
            else
              echo "::debug::aptly -config="$APTLY_CFG" -ignore-signatures ${FILTER_ARGS[*]} ${ADDITIONAL_FILTER} -architectures="${{ matrix.arch }}" mirror create "$MIRROR" "$URL" "$DIST""
              # shellcheck disable=SC2086
              aptly -config="$APTLY_CFG" -ignore-signatures "${FILTER_ARGS[@]}" $ADDITIONAL_FILTER -architectures="${{ matrix.arch }}" mirror create "$MIRROR" "$URL" "$DIST"
            fi
            echo "::debug::Mirror created successfully"

            # Update mirror with retry logic for EOF errors
            echo "::debug::Updating mirror..."
            MAX_RETRIES=3
            RETRY_COUNT=0
            UPDATE_SUCCESS=false

            while [[ $RETRY_COUNT -lt $MAX_RETRIES && "$UPDATE_SUCCESS" == "false" ]]; do
              if aptly -config="$APTLY_CFG" -max-tries=20 -ignore-signatures mirror update "$MIRROR"; then
                echo "::debug::Mirror updated successfully"
                UPDATE_SUCCESS=true
              else
                RETRY_COUNT=$((RETRY_COUNT + 1))
                if [[ $RETRY_COUNT -lt $MAX_RETRIES ]]; then
                  echo "::warning::Mirror update failed (attempt $RETRY_COUNT/$MAX_RETRIES), retrying..."
                  sleep 2
                  # Recreate mirror if it got corrupted
                  echo "::debug::Recreating mirror after failure..."
                  aptly -config="$APTLY_CFG" mirror drop "$MIRROR" || true
                  if [[ -n "$COMPONENTS" ]]; then
                    # shellcheck disable=SC2086
                    aptly -config="$APTLY_CFG" -ignore-signatures "${FILTER_ARGS[@]}" $ADDITIONAL_FILTER -architectures="${{ matrix.arch }}" mirror create "$MIRROR" "$URL" "$DIST" $COMPONENTS
                  else
                    # shellcheck disable=SC2086
                    aptly -config="$APTLY_CFG" -ignore-signatures "${FILTER_ARGS[@]}" $ADDITIONAL_FILTER -architectures="${{ matrix.arch }}" mirror create "$MIRROR" "$URL" "$DIST"
                  fi
                else
                  echo "::error::Mirror update failed after $MAX_RETRIES attempts"
                  exit 1
                fi
              fi
            done

            # Snapshot
            echo "::debug::Creating snapshot..."
            aptly -config="$APTLY_CFG" snapshot create "$MIRROR" from mirror "$MIRROR"
            echo "::debug::Snapshot created successfully"

            # Publish
            echo "::debug::Publishing snapshot..."
            aptly -config="$APTLY_CFG" publish -architectures="${{ matrix.arch }}" -batch=true snapshot "$MIRROR"
            echo "::debug::Snapshot published successfully"

            # Keep only latest version of each package

            ROOTS=($SOURCE)

            best_for_pkg_in_dir() {
              local dir="$1" pkg="$2"
              local best_ver="" best_file="" f ver

              while IFS= read -r -d '' f; do
                f="$(basename "$f")"
                ver="${f#${pkg}_}"; ver="${ver%%_*}"
                if [[ -z "$best_ver" ]] || dpkg --compare-versions "$ver" gt "$best_ver"; then
                  best_ver="$ver"
                  best_file="$f"
                fi
              done < <(find "$dir" -maxdepth 1 -type f -name "${pkg}_*.deb" -print0)

              [[ -n "$best_file" ]] && printf '%s\n' "$best_file"
            }

            for root in "${ROOTS[@]}"; do
              [[ -d "$root" ]] || continue

              # Process each directory that contains .deb files
              while IFS= read -r -d '' dir; do
                # List unique package names in this dir
                mapfile -t pkgs < <(find "$dir" -maxdepth 1 -type f -name '*.deb' -printf '%f\n' \
                  | sed -E 's/_.*//' | sort -u)

                ( cd "$dir"
                  for pkg in "${pkgs[@]}"; do
                    best="$(best_for_pkg_in_dir "$dir" "$pkg")"
                    [[ -n "$best" ]] || continue

                    # Delete all other versions of that package in this dir
                    while IFS= read -r -d '' f; do
                      b="$(basename "$f")"
                      [[ "$b" == "$best" ]] && continue
                      rm -f -- "$b"
                    done < <(find "$dir" -maxdepth 1 -type f -name "${pkg}_*.deb" -print0)

                    echo "[$dir] kept: $best"
                  done
                )
              done < <(find "$root" -type f -name '*.deb' -printf '%h\0' | sort -zu)
            done
          fi

          # Repack deb files with Armbian version
          if [[ "${{ matrix.name }}" == "firefox" ]]; then
            apt-get install -y devscripts
            DEBS=($(sudo find "${SOURCE}"* -type f -name '*firefox_*.deb'))
            for d in "${DEBS[@]}"; do
              BEFORE=$(deb-reversion -c ${d} -s armbian)
              # Add epoch 9
              AFTER=9:$(echo $BEFORE | cut -d":" -f2)
              echo "$d : $BEFORE -> $AFTER"
              DEBEMAIL=info@armbian.com deb-reversion -v $AFTER -s armbian $d
              rm $d
              mv *.deb ${SOURCE}
            done
          fi

          # Store info to GitHub Actions
          AFTER_VERSION=$(find "$SOURCE" -type f -name "${INSTALL%% *}*.deb" -exec dpkg-deb -f {} Version \; | sort | uniq | tail -n 1 | cut -d":" -f2)
          if [[ -z $AFTER_VERSION ]]; then
            AFTER_VERSION=$(find "$SOURCE" -type f -name "*.deb" -exec dpkg-deb -f {} Version \; | sort | uniq | tail -n 1 | cut -d":" -f2)
          fi
          PKG_LINES="$(find "$SOURCE" -type f -name "*.deb" -printf "%f\n" 2>/dev/null | sort | sed 's/$/<br>/')"
          echo "AFTER_VERSION=${AFTER_VERSION}" >> $GITHUB_OUTPUT

          # Determine if update is needed
          UPDATE_NEEDED="false"
          if dpkg --compare-versions "$AFTER_VERSION" gt "$BEFORE_VERSION"; then
            UPDATE_NEEDED="true"
          fi
          echo "UPDATE_NEEDED=${UPDATE_NEEDED}" >> $GITHUB_OUTPUT

          # Copy packages to appropriate output directories
          if [[ ${TARGET} == main ]]; then
            # Copy to main repository directories
            if grep -qE 'B' <<< "$REPOSITORY"; then
              find $SOURCE -type f -name "*.deb" -exec cp -v {} build/output/debs-beta/ \;
            fi
            if grep -qE 'S' <<< "$REPOSITORY"; then
              find $SOURCE -type f -name "*.deb" -exec cp -v {} build/output/debs/ \;
            fi
          else
            # Copy to specific release directories
            if grep -qE 'B' <<< "$REPOSITORY"; then
              find $SOURCE -type f -name "*.deb" -exec cp -v {} build/output/debs-beta/extra/${{ matrix.release }}-${TARGET} \;
            fi
            if grep -qE 'S' <<< "$REPOSITORY"; then
              find $SOURCE -type f -name "*.deb" -exec cp -v {} build/output/debs/extra/${{ matrix.release }}-${TARGET} \;
            fi
          fi

          # Always sync to debs-beta (before potential early exit)
          # Note: StrictHostKeychecking=no is used here; consider using proper known_hosts in production
          rsync -e "ssh -o StrictHostKeychecking=no -p ${{ secrets.HOST_UPLOAD_PORT }}" \
            -arvc build/output/debs-beta/ ${{ secrets.HOST_UPLOAD_USER }}@${{ secrets.HOST_UPLOAD }}:storage/debs-beta

          # Upload to repository if version changed
          if dpkg --compare-versions "$AFTER_VERSION" gt "$BEFORE_VERSION"; then
            # Generate summary table for updates
            echo '| name | method | arch | release | needs_qemu | target | before | after | updating |' >> $GITHUB_STEP_SUMMARY
            echo '|--------|-------|------|---------|------------|--------|--------|--------|----------|' >> $GITHUB_STEP_SUMMARY
            echo "| ${{ matrix.name }} | ${{ matrix.method }} | ${{ matrix.arch }} | ${{ matrix.release }} | ${{ matrix.needs_qemu }} | ${{ matrix.target }} | $BEFORE_VERSION | $AFTER_VERSION | âœ… |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "packages: <br><code>$PKG_LINES</code>" >> $GITHUB_STEP_SUMMARY

            # Upload packages
            # Note: StrictHostKeychecking=no is used here; consider using proper known_hosts in production
            rsync -e "ssh -o StrictHostKeychecking=no -p ${{ secrets.HOST_UPLOAD_PORT }}" \
              -arvc build/output/debs/ ${{ secrets.HOST_UPLOAD_USER }}@${{ secrets.HOST_UPLOAD }}:storage/debs

          elif [[ "${{ inputs.HIDE_NO_UPDATE }}" == "true" ]]; then
            # Exit if HIDE_NO_UPDATE is enabled and no update needed
            echo "::notice::No update needed for ${{ matrix.name }} on ${{ matrix.arch }}, exiting early"
            exit 0
          fi

  clean:
    name: "Clean"
    needs: [download,postclean]
    if: ${{ always() }}
    runs-on: ${{ inputs.BUILD_RUNNER }}
    steps:

      - name: Clean artifacts
        uses: geekyeggo/delete-artifact@v4
        with:
          name: assets-for-download
          failOnError: false
